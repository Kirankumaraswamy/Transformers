INFO:root:training_config[num_of_optimizers]:2
INFO:root:training_config[num_of_epochs]:20
INFO:root:training_config[batch_size]:1000
INFO:root:training_config[num_of_layers]:6
INFO:root:training_config[model_dims]:512
INFO:root:training_config[num_of_heads]:8
INFO:root:training_config[dropout_prob]:0.1
INFO:root:training_config[smoothing_value]:0.1
INFO:root:training_config[scheduler1]:paper
INFO:root:training_config[scheduler2]:paper
INFO:root:training_config[optimizer_1_lr]:0.1
INFO:root:training_config[num_warmup_steps1]:4000
INFO:root:training_config[optimizer_1_beta1]:0.9
INFO:root:training_config[optimizer_1_beta2]:0.98
INFO:root:training_config[optimizer_1_eps]:1e-09
INFO:root:training_config[optimizer_2_lr]:0.1
INFO:root:training_config[num_warmup_steps2]:4000
INFO:root:training_config[optimizer_2_beta1]:0.8
INFO:root:training_config[optimizer_2_beta2]:0.88
INFO:root:training_config[optimizer_2_eps]:1e-09
INFO:root:training_config[language_direction]:E2G
INFO:root:training_config[dataset_path]:/home/kiran/kiran/dl_lab/project/transformers/lab_transformer/utils_train/../data
INFO:root:training_config[console_log_freq]:10
INFO:root:training_config[checkpoint_freq]:5
INFO:root:
STARTING TRAIN CALL
INFO:root:torch.device: cpu
INFO:root:SETUP NUM OPTIMIZERS: 2
INFO:root:Optimizer 1 is paper
INFO:root:Optimizer 2 is paper
INFO:root:Transformer training: time elapsed= 3.15 [s] | epoch=1 | batch= 1 | target tokens/batch= 72.0
INFO:root:Transformer training: time elapsed= 33.96 [s] | epoch=1 | batch= 11 | target tokens/batch= 810.5999755859375
INFO:root:Transformer training: time elapsed= 64.81 [s] | epoch=1 | batch= 21 | target tokens/batch= 756.7999877929688
INFO:root:Transformer training: time elapsed= 92.32 [s] | epoch=1 | batch= 31 | target tokens/batch= 766.7000122070312
INFO:root:Transformer training: time elapsed= 121.22 [s] | epoch=1 | batch= 41 | target tokens/batch= 796.0
INFO:root:Transformer training: time elapsed= 155.48 [s] | epoch=1 | batch= 51 | target tokens/batch= 826.9000244140625
INFO:root:Transformer training: time elapsed= 187.45 [s] | epoch=1 | batch= 61 | target tokens/batch= 739.7000122070312
INFO:root:Transformer training: time elapsed= 221.49 [s] | epoch=1 | batch= 71 | target tokens/batch= 805.5999755859375
INFO:root:Transformer training: time elapsed= 254.90 [s] | epoch=1 | batch= 81 | target tokens/batch= 801.0
INFO:root:Transformer training: time elapsed= 288.79 [s] | epoch=1 | batch= 91 | target tokens/batch= 776.5999755859375
INFO:root:Transformer training: time elapsed= 321.73 [s] | epoch=1 | batch= 101 | target tokens/batch= 803.5
INFO:root:Transformer training: time elapsed= 350.31 [s] | epoch=1 | batch= 111 | target tokens/batch= 821.0999755859375
INFO:root:Transformer training: time elapsed= 376.52 [s] | epoch=1 | batch= 121 | target tokens/batch= 719.2999877929688
INFO:root:Transformer training: time elapsed= 404.99 [s] | epoch=1 | batch= 131 | target tokens/batch= 763.0999755859375
INFO:root:Transformer training: time elapsed= 436.85 [s] | epoch=1 | batch= 141 | target tokens/batch= 765.0
INFO:root:Transformer training: time elapsed= 469.22 [s] | epoch=1 | batch= 151 | target tokens/batch= 821.4000244140625
INFO:root:Transformer training: time elapsed= 503.59 [s] | epoch=1 | batch= 161 | target tokens/batch= 834.2000122070312
INFO:root:Transformer training: time elapsed= 533.64 [s] | epoch=1 | batch= 171 | target tokens/batch= 798.2000122070312
INFO:root:Transformer training: time elapsed= 564.33 [s] | epoch=1 | batch= 181 | target tokens/batch= 810.7000122070312
INFO:root:Transformer training: time elapsed= 595.40 [s] | epoch=1 | batch= 191 | target tokens/batch= 839.7999877929688
INFO:root:Transformer training: time elapsed= 627.40 [s] | epoch=1 | batch= 201 | target tokens/batch= 790.2999877929688
INFO:root:Transformer training: time elapsed= 660.14 [s] | epoch=1 | batch= 211 | target tokens/batch= 768.5999755859375
INFO:root:Transformer training: time elapsed= 693.19 [s] | epoch=1 | batch= 221 | target tokens/batch= 810.0
INFO:root:Transformer training: time elapsed= 726.36 [s] | epoch=1 | batch= 231 | target tokens/batch= 787.7999877929688
INFO:root:Transformer training: time elapsed= 759.18 [s] | epoch=1 | batch= 241 | target tokens/batch= 790.5999755859375
INFO:root:Transformer training: time elapsed= 791.98 [s] | epoch=1 | batch= 251 | target tokens/batch= 758.9000244140625
INFO:root:Transformer training: time elapsed= 823.40 [s] | epoch=1 | batch= 261 | target tokens/batch= 817.9000244140625
INFO:root:Transformer training: time elapsed= 855.14 [s] | epoch=1 | batch= 271 | target tokens/batch= 802.0
INFO:root:Transformer training: time elapsed= 884.30 [s] | epoch=1 | batch= 281 | target tokens/batch= 722.9000244140625
INFO:root:Transformer training: time elapsed= 916.54 [s] | epoch=1 | batch= 291 | target tokens/batch= 816.7000122070312
INFO:root:Transformer training: time elapsed= 948.85 [s] | epoch=1 | batch= 301 | target tokens/batch= 798.9000244140625
INFO:root:Transformer training: time elapsed= 978.58 [s] | epoch=1 | batch= 311 | target tokens/batch= 734.5999755859375
INFO:root:Transformer training: time elapsed= 1008.32 [s] | epoch=1 | batch= 321 | target tokens/batch= 752.9000244140625
INFO:root:Transformer training: time elapsed= 1040.70 [s] | epoch=1 | batch= 331 | target tokens/batch= 799.7000122070312
INFO:root:Transformer training: time elapsed= 1073.60 [s] | epoch=1 | batch= 341 | target tokens/batch= 770.2999877929688
INFO:root:Transformer training: time elapsed= 1105.72 [s] | epoch=1 | batch= 351 | target tokens/batch= 795.2000122070312
INFO:root:Transformer training: time elapsed= 1138.68 [s] | epoch=1 | batch= 361 | target tokens/batch= 789.7000122070312
INFO:root:Transformer training: time elapsed= 1168.78 [s] | epoch=1 | batch= 371 | target tokens/batch= 715.0
INFO:root:Transformer training: time elapsed= 1201.31 [s] | epoch=1 | batch= 381 | target tokens/batch= 801.7999877929688
INFO:root:Transformer training: time elapsed= 1231.67 [s] | epoch=1 | batch= 391 | target tokens/batch= 798.7999877929688
INFO:root:Transformer training: time elapsed= 1264.28 [s] | epoch=1 | batch= 401 | target tokens/batch= 758.5999755859375
INFO:root:Transformer training: time elapsed= 1299.14 [s] | epoch=1 | batch= 411 | target tokens/batch= 809.5999755859375
INFO:root:Transformer training: time elapsed= 1333.46 [s] | epoch=1 | batch= 421 | target tokens/batch= 790.5
INFO:root:Transformer training: time elapsed= 1367.76 [s] | epoch=1 | batch= 431 | target tokens/batch= 818.9000244140625
INFO:root:Transformer training: time elapsed= 1401.63 [s] | epoch=1 | batch= 441 | target tokens/batch= 764.0999755859375
INFO:root:Transformer training: time elapsed= 1435.22 [s] | epoch=1 | batch= 451 | target tokens/batch= 815.4000244140625
INFO:root:Transformer training: time elapsed= 1462.40 [s] | epoch=1 | batch= 461 | target tokens/batch= 805.5
INFO:root:Transformer training: time elapsed= 1489.56 [s] | epoch=1 | batch= 471 | target tokens/batch= 834.5999755859375
INFO:root:Transformer training: time elapsed= 1516.45 [s] | epoch=1 | batch= 481 | target tokens/batch= 736.7999877929688
INFO:root:Transformer training: time elapsed= 1543.00 [s] | epoch=1 | batch= 491 | target tokens/batch= 803.7999877929688
INFO:root:Transformer training: time elapsed= 1569.11 [s] | epoch=1 | batch= 501 | target tokens/batch= 834.9000244140625
INFO:root:Transformer training: time elapsed= 1596.50 [s] | epoch=1 | batch= 511 | target tokens/batch= 736.7000122070312
INFO:root:Transformer training: time elapsed= 1624.20 [s] | epoch=1 | batch= 521 | target tokens/batch= 802.9000244140625
INFO:root:Transformer training: time elapsed= 1649.65 [s] | epoch=1 | batch= 531 | target tokens/batch= 766.2999877929688
INFO:root:Transformer training: time elapsed= 1675.83 [s] | epoch=1 | batch= 541 | target tokens/batch= 777.2999877929688
INFO:root:Transformer training: time elapsed= 1703.50 [s] | epoch=1 | batch= 551 | target tokens/batch= 818.9000244140625
